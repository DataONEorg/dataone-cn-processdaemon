LogAggregator.active=TRUE
LogAggregator.solrUrl=http://localhost:8983/solr/event_core
LogAggregator.solrUrlPath=/cn/v1/query/logsolr
LogAggregator.logRecords_batch_size=1000
# cn_base_url should point to metacat in order to grab the logs maintained there
LogAggregator.cn_base_url=https://SERVER_NAME/metacat/d1/cn
LogAggregator.delayStartOffset.minutes=10
# the field name of the period to calculate interval between trigger 
# firings of logAggregation jobs. Valid values are hours, minutes or seconds
LogAggregator.triggerInterval.periodField=hours
LogAggregator.triggerInterval.period=24
LogAggregator.geoIPdbName=/etc/dataone/process/GeoLiteCity.dat
# List of web robots used for COUNTER compliance checking.
# The 'strict' list is maintained and published by the COUNTER standard project and
# was initially downloaded on 2015-01-31 
# from http://www.projectcounter.org/r4/COUNTER_robot_txt_list_Jan_2011.txt
LogAggregator.fullWebRobotListFilePath=/etc/dataone/process/fullWebRobotList.txt
# The 'loose' list is a subset of the full list and has user agents
# such as 'java' and 'perl' removed from the list.
LogAggregator.partialWebRobotListFilePath=/etc/dataone/process/partialWebRobotList.txt
# Time interval (in seconds) between read events that must be observed for
# the event to not be considered a 'repeat visit'
LogAggregator.repeatVisitIntervalSeconds=30
# Maximum number of entries to allow in the read event cache before it is purged
LogAggregator.readEventCacheMax=2000
# Perform a check on the log entry, inspecting the IP address to see if it corresponds to the
# known address of a web robot
LogAggregator.doWebRobotIPcheck=true
# The file containing a list of web robots and associated IP addresses or ranges (as CIDR)
LogAggregator.webRobotIPsFilePath=/etc/dataone/process/webRobotIPs.csv
# The file containing a list of DataONE IP addresses
LogAggregator.DataONE_IPsFilePath=/etc/dataone/process/DataONE_IPs.csv